#!/usr/bin/env python3

import argparse
from http.server import BaseHTTPRequestHandler
import socketserver
from typing import Tuple
import urllib.request
from utils import *
import os
import csv

DISK_SIZE_LIMIT = 20000000


class ReplicaHTTPServer(BaseHTTPRequestHandler):
    """
    This class inherits from the BaseHTTPRequestHandler in the 'http.server' library and outlines logic for
    a GET request on the replica HTTP server.
    """

    def __init__(self, request: bytes, client_address: Tuple[str, int], server: socketserver.BaseServer):
        super().__init__(request, client_address, server)  # type: ignore

    def _send_information_over(self, response_code, html_string):
        """
        Helper method to send information to the client. Put this into a function because
        the contents of this function are used multiple times.

        Args:
            response_code: the response code to send over
            html_string: the response message to send over.
        """
        self.send_response(response_code)
        self.send_header('Content-type', 'text/html')
        self.end_headers()
        self.wfile.write(bytes(html_string, "utf-8"))

    def do_GET(self):
        """
        This method is an override of the do_GET function specified in the BaseHTTPRequestHandler class.
        If the data we are looking for based on the path exists in our cache, then we send that data over. Otherwise,
        we send the data from the origin server.
        """

        current_directory = get_current_directory()

        filepath = self.path[1:]

        # if the file we're looking for exists in the disk cache, then pull the data
        # from there, otherwise go to the Origin server and pull the data from there.
        if filepath and does_file_exist(f'{CACHE_DIRECTORY}/{filepath}'):
            # open the file from the cache
            with open(f'{current_directory}/{CACHE_DIRECTORY}/{filepath}', 'r') as file:
                file_lines = file.readlines()

            # join the string list and send the data back out.
            joined_result = "".join(file_lines)
            self._send_information_over(200, joined_result)
            return

        try:
            # actual path to the resource on the Origin server
            actual_resource_path = f'http://{ORIGIN_SERVER}/{filepath}'

            # contact the Origin server for the requested resource
            with urllib.request.urlopen(actual_resource_path) as response:
                # Extract the data from te origin server and the headers.
                data = response.read()
                headers = response.info()
                self._send_information_over(response.status, data.decode())

        except Exception as e:
            # print("Unble to retrieve data from the origin server. Please request for the resource again")
            self._send_information_over(400, "<html><body><h1>Unble to retrieve data from the origin server. "
                                        "Please request for the resource again</h1></body></html>")
            # ============================================================================================
            return

        # exit if filepath is empty i.e root / path.
        if not filepath:
            return

        # we need to cache the data that we just found from the origin server, but if the size of the
        # current directory plus the new file size is greater than the disk size limit, we need to remove
        # certain files based on priority.
        if int(size_of_cache_directory()) + int(headers['Content-Length']) > DISK_SIZE_LIMIT:
            with open('pageviews.csv', newline='') as csvfile:
                CSV_READER = csv.DictReader(csvfile)
                CSV_READER = list(CSV_READER)

                # loop over all the rows in the csv, but in reversed order because we want to remove the
                # lowest priority files first.
                for row in reversed(CSV_READER):
                    # the csv doesn't have underscores in it, so we need to modify each file name.
                    row['article'] = row['article'].replace(' ', '_')

                    # find the path for the following file and if it actually exists in our cache, we remove
                    # the file from our cache.
                    directory = check_file_in_directory(
                        CACHE_DIRECTORY, row['article'])
                    if directory is not None:
                        os.remove(f'{current_directory}/{directory}')

                    if int(size_of_cache_directory()) + int(headers['Content-Length']) > DISK_SIZE_LIMIT:
                        continue
                    else:
                        break

            # even after removing all the least priority files, we still want to make sure that we have the
            # space to add our new file. We do this by removing the files that have been in the cache the
            # longest
            list_of_files = remove_old_files()
            i = 0
            while i < len(list_of_files) and \
                    int(size_of_cache_directory()) + int(headers['Content-Length']) > DISK_SIZE_LIMIT:
                print("removing ", list_of_files[i])
                os.remove(list_of_files[i])
                i += 1

            # extract the directory path and the name of the file and make the directory.
            dir_path, file_name = os.path.split(filepath)
            mk_dir(f'{CACHE_DIRECTORY}/{dir_path}')

            with open(f'{CACHE_DIRECTORY}/{filepath}', "wb") as file:
                # Write the content of the file to the file we're creating and close the file out.
                file.write(data)
                file.close()


def main(server_port_number: int):
    """
    The entry point into the http server.
    Args:
        server_port_number: the port number this http server is listening/sending on

    """
    # create the cache directory if it doesn't exist, because this is where we
    # store all the cached data.
    mk_dir(CACHE_DIRECTORY)

    with socketserver.TCPServer(("0.0.0.0", server_port_number), ReplicaHTTPServer) as httpd:
        print("Serving at port", server_port_number)
        httpd.serve_forever()


if __name__ == "__main__":

    # specify the port number and the origin server

    DEFAULT_PORT = 20200
    DEFAULT_ORIGIN_SERVER = 'cs5700cdnorigin.ccs.neu.edu:8080'

    # Define the command line arguments
    parser = argparse.ArgumentParser(
        description="Determine HTTP Server arguments")
    parser.add_argument('-p', dest="port", action='store', type=int,
                        help="Port Number (default: %(default)s)", default=DEFAULT_PORT)
    parser.add_argument('-o', dest="origin", action='store', type=str,
                        help="The Origin Server (default: %(default)s)", default=DEFAULT_ORIGIN_SERVER)

    # Parse the arguments
    args = parser.parse_args()

    # Set value for origin server
    ORIGIN_SERVER = args.origin

    # Call the main method with the specified port and origin
    main(args.port)
